import warnings
import train
from random import shuffle
from os import listdir
import pickle
import pandas as pd
import numpy as np
from datetime import datetime

def predictor(hourOfDay, dayOfWeek, monthOfYear, meter_reading, lag1, lag2, lag3, dir_, n):
    """
    Uses random saved models in directory to make an anomaly prediction
    :param hourOfDay: Feature 1: hour of day
    :param dayOfWeek: Feature 2: day of week
    :param monthOfYear: Feature 3: month of year
    :param meter_reading: Feature 4: meter reading
    :param lag1: Feature 5: lag1
    :param lag2: Feature 6: lag2
    :param lag3: Feature 7: lag3
    :param dir_: Directory with .sav files of models (and only .sav files)
    :param n: Number of random .sav files of models to use
    :return: Float: 0 to 1 representing whether the features listed is an anomaly or not based on the random models' consensus
    """
    listOfFiles = listdir(dir_)
    shuffle(listOfFiles)
    modelsToUse = listOfFiles[:n]

    votes = []
    for model in modelsToUse:
        loaded_model = pickle.load(open(dir_ + "\\" + model, 'rb'))
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            votes.append(train.predict(loaded_model, [hourOfDay, dayOfWeek, monthOfYear, meter_reading, lag1, lag2, lag3]))

    return (sum(votes) / len(votes))[0]

def processDF(df, n):
    """
    Processes Pandas Dataframe to predict whether each row is an anomaly
    :param df: Pandas DataFrame; 7 columns: hourOfDay, dayOfWeek, monthOfYear, meter_reading, lag1, lag2, lag3
    :param n: int; number of random models to use, the larger n is the longer the processing time
    :return: list; List of anomaly probabilities
    """
    anomalies = []
    for i,j in df.iterrows():
        currRow = (np.asarray(j))
        if True in pd.isna(currRow):
            break
        anomalies.append(predictor(currRow[0],currRow[1],currRow[2],currRow[3],currRow[4],currRow[5],currRow[6], "models", n))

    return anomalies


def processCSV(dir_, timestamp_col, value_col, n, append=True):
    """
    Imports CSV file as Pandas DataFrame ready for processing by anomaly predictor
    :param dir_: str: Directory of CSV file
    :param timestamp_col: str; Column name of timestamp column
    :param value_col: str; Column name of value column (meter reading)
    :param n: int; number of random models to use, the larger n is the longer the processing time
    :param append: bool; default=True; If true, then export anomaly column appended onto original CSV file columns
    :return:Pandas Dataframe; DataFrame generated by CSV file with anomaly column
    """
    # Create df2
    df = pd.read_csv(dir_)
    df2 = pd.DataFrame({"hourOfDay":[]})
    df2['hourOfDay'] = pd.to_datetime(df[timestamp_col]).dt.hour
    df2['dayOfWeek'] = pd.to_datetime(df[timestamp_col]).dt.dayofweek
    df2['monthOfYear'] = pd.to_datetime(df[timestamp_col]).dt.month
    df2['meter_reading'] = df[value_col]
    for lag in range(1,4):
        df2["lag%s" % lag] = (df[value_col].shift(-lag))[:-lag]

    anomalyCol = pd.DataFrame(processDF(df2, n))
    dir2 = dir_[:-4] + "-processed.csv"
    if append:
        df["anomaly"] = anomalyCol
        df.to_csv(dir2)
    else:
        df.to_csv(dir2)
    print("Done: "+dir2)

    return df2

